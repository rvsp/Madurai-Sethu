{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trX = np.linspace(-1, 1, 101)\n",
    "trY = 3 * trX + np.random.randn(*trX.shape) * 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.  , -0.98, -0.96, -0.94, -0.92, -0.9 , -0.88, -0.86, -0.84,\n",
       "       -0.82, -0.8 , -0.78, -0.76, -0.74, -0.72, -0.7 , -0.68, -0.66,\n",
       "       -0.64, -0.62, -0.6 , -0.58, -0.56, -0.54, -0.52, -0.5 , -0.48,\n",
       "       -0.46, -0.44, -0.42, -0.4 , -0.38, -0.36, -0.34, -0.32, -0.3 ,\n",
       "       -0.28, -0.26, -0.24, -0.22, -0.2 , -0.18, -0.16, -0.14, -0.12,\n",
       "       -0.1 , -0.08, -0.06, -0.04, -0.02,  0.  ,  0.02,  0.04,  0.06,\n",
       "        0.08,  0.1 ,  0.12,  0.14,  0.16,  0.18,  0.2 ,  0.22,  0.24,\n",
       "        0.26,  0.28,  0.3 ,  0.32,  0.34,  0.36,  0.38,  0.4 ,  0.42,\n",
       "        0.44,  0.46,  0.48,  0.5 ,  0.52,  0.54,  0.56,  0.58,  0.6 ,\n",
       "        0.62,  0.64,  0.66,  0.68,  0.7 ,  0.72,  0.74,  0.76,  0.78,\n",
       "        0.8 ,  0.82,  0.84,  0.86,  0.88,  0.9 ,  0.92,  0.94,  0.96,\n",
       "        0.98,  1.  ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.36961583e+00, -2.71873267e+00, -3.18775230e+00, -2.78758899e+00,\n",
       "       -2.61502265e+00, -2.27175075e+00, -2.92396705e+00, -2.56060955e+00,\n",
       "       -2.49341225e+00, -2.64542655e+00, -1.70993992e+00, -2.19980009e+00,\n",
       "       -2.28863090e+00, -2.32682646e+00, -2.13779408e+00, -1.49498366e+00,\n",
       "       -1.95056497e+00, -2.56560693e+00, -2.15966720e+00, -1.70399225e+00,\n",
       "       -1.65450660e+00, -1.92201144e+00, -1.62337912e+00, -1.19351385e+00,\n",
       "       -1.97698383e+00, -1.95680135e+00, -1.19947045e+00, -1.08377282e+00,\n",
       "       -7.32619292e-01, -1.25923985e+00, -7.80254432e-01, -1.26171968e+00,\n",
       "       -1.28808585e+00, -6.88903909e-01, -1.09655845e+00, -1.11189542e+00,\n",
       "       -7.42595902e-01, -1.25195745e+00, -7.86085692e-01, -2.92415873e-01,\n",
       "       -1.34186357e+00, -9.16849572e-01, -5.96943724e-01, -1.26789946e-01,\n",
       "       -6.61759028e-04, -1.52580822e-01,  9.73434976e-02,  2.56132378e-01,\n",
       "       -2.09976971e-02, -6.24774201e-01, -3.05037742e-01,  9.12166781e-01,\n",
       "        1.74379552e-02,  8.11632645e-02, -9.17979482e-02,  3.49719304e-03,\n",
       "        1.67969343e-01,  9.16157109e-01,  7.13371043e-01,  3.84646830e-01,\n",
       "        5.42535771e-01,  1.27792766e+00,  1.38451496e+00,  1.29553847e+00,\n",
       "        9.58975898e-01,  4.28912970e-01,  1.17404063e+00,  1.08333472e+00,\n",
       "        6.27815411e-01,  1.78503740e+00,  1.31298134e+00,  8.55969808e-01,\n",
       "        8.86621912e-01,  2.19644810e+00,  1.25425500e+00,  1.35791404e+00,\n",
       "        1.18893846e+00,  1.87463945e+00,  1.40295378e+00,  1.55291685e+00,\n",
       "        1.72947232e+00,  2.21585426e+00,  2.45289164e+00,  2.47543838e+00,\n",
       "        2.21989452e+00,  2.38777719e+00,  2.01756056e+00,  2.17735954e+00,\n",
       "        1.99845991e+00,  2.35592140e+00,  2.38807312e+00,  3.37238458e+00,\n",
       "        2.80128636e+00,  3.10302410e+00,  3.03106954e+00,  3.04848878e+00,\n",
       "        2.44203856e+00,  2.71333740e+00,  2.44733575e+00,  3.67027844e+00,\n",
       "        3.13448379e+00])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Dense(input_dim=1, output_dim=1, init='uniform', activation='linear'))\n",
    "model.add(Dense(input_dim=1, units=1, kernel_initializer='uniform', activation='linear'))\n",
    "model.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression model is initialized with weight w: 3.05, b: 0.07\n"
     ]
    }
   ],
   "source": [
    "weights = model.layers[0].get_weights()\n",
    "w_init = weights[0][0][0]\n",
    "b_init = weights[1][0]\n",
    "print('Linear regression model is initialized with weight w: %.2f, b: %.2f' % (w_init, b_init))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.1295\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.1298\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.1295\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.1298\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.1298\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.1295\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.1295\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.1295\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.1295\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.1299\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.1298\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.1297\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.1296\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.1297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f053416f160>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trX, trY, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression model is trained to have final weight w: 3.04, b: 0.07\n"
     ]
    }
   ],
   "source": [
    "weights = model.layers[0].get_weights()\n",
    "w_final = weights[0][0][0]\n",
    "b_final = weights[1][0]\n",
    "print('Linear regression model is trained to have final weight w: %.2f, b: %.2f' % (w_final, b_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
